name,ring,quadrant,isNew,description
Applying product management to internal platforms,Adopt,Techniques,FALSE,"<p>More and more companies are building internal platforms to roll out new digital solutions quickly and efficiently. Companies that succeed with this strategy are <strong>applying product management to internal platforms</strong>. This means establishing empathy with internal consumers (the development teams) and collaborating with them on the design. Platform product managers create roadmaps and ensure the platform delivers value to the business and enhances the developer experience. Unfortunately, we're also seeing less successful approaches, where teams create a platform in the void, based on unverified assumptions and without internal customers. These platforms, often despite aggressive internal tactics, end up being underutilized and a drain on the organization's delivery capability. As usual, good product management is all about building products that consumers love.</p>"
Infrastructure as code,Adopt,Techniques,FALSE,"<p>Although <strong>infrastructure as code</strong> is a relatively old technique (we’ve featured it in the Radar in 2011), it has become vitally important in the modern cloud era where the act of setting up infrastructure has become the passing of configuration instructions to a cloud platform. When we say ""as code"" we mean that all the good practices we've learned in the software world should be applied to infrastructure. Using source control, adhering to the <a href=""https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"">DRY principle</a>, modularization, maintainability, and using automated testing and deployment are all critical practices. Those of us with a deep software and infrastructure background need to empathize with and support colleagues who do not. Saying ""treat infrastructure like code"" isn't enough; we need to ensure the hard-won learnings from the software world are also applied consistently throughout the infrastructure realm.</p>"
Decentralized identity,Assess,Techniques,TRUE,"<p>Since the birth of the internet, the technology landscape has experienced an accelerated evolution toward decentralization. While protocols such as HTTP and architectural patterns such as <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> or <a href=""/radar/techniques/data-mesh"">data mesh</a> enable decentralized implementations, identity management remains centralized. The emergence of distributed ledger technology (DLT), however, provides the opportunity to enable the concept of <strong>decentralized identity</strong>. In a decentralized identity system, entities — that is, discrete identifiable units such as people, organizations and things — are free to use any shared root of trust. In contrast, conventional identity management systems are based on centralized authorities and registries such as corporate directory services, certificate authorities or domain name registries.</p>

<p>The development of <a href=""https://www.w3.org/TR/did-core/"">decentralized identifiers</a> — globally unique, persistent and <em>self-sovereign identifiers</em> that are cryptographically verifiable — is a major enabling standard. Although scaled implementations of decentralized identifiers in the wild are still rare, we're excited by the premise of this movement and have started using the concept in our architecture. For the latest experiments and industry collaborations, check out <a href=""https://identity.foundation/"">Decentralized Identity Foundation</a>.</p>"
Declarative data pipeline definition,Assess,Techniques,TRUE,"<p>Many data pipelines are defined in a large, more or less imperative script written in Python or Scala. The script contains the logic of the individual steps as well as the code chaining the steps together. When faced with a similar situation in Selenium tests, developers discovered the Page Object pattern, and later many behavior-driven development (BDD) frameworks implemented a split between step definitions and their composition. Some teams are now experimenting with bringing the same thinking to data engineering. A separate <strong>declarative data pipeline definition</strong>, maybe written in YAML, contains only the declaration and sequence of steps. It states input and output data sets but refers to scripts if and when more complex logic is needed. With <a href=""https://github.com/binaryaffairs/a-la-mode"">A La Mode</a>, we're seeing the first open source tool appear in this space.</p>"
DeepWalk,Assess,Techniques,TRUE,"<p><strong><a href=""https://github.com/phanein/deepwalk"">DeepWalk</a></strong> is an algorithm that helps apply machine learning on graphs. When working on data sets that are represented as graphs, one of the key problems is to extract features from the graph. This is where DeepWalk can help. It uses SkipGram to construct node embeddings by viewing the graph as a language where each node is a unique word in the language and random walks of finite length on the graph constitutes a sentence. These embeddings can then be used by various ML models. DeepWalk is one of the techniques we're trialling on some of our projects where we've needed to apply machine learning on graphs.</p>"
Managing stateful systems via container orchestration,Assess,Techniques,TRUE,"<p>We recommend caution in <strong>managing stateful systems via container orchestration</strong> platforms such as Kubernetes. Some databases are not built with native support for orchestration — they don't expect a scheduler to kill and relocate them to a different host. Building a highly available service on top of such databases is not trivial, and we still recommend running them on bare metal hosts or a virtual machine (VM) rather than to force-fit them into a container orchestration platform.</p>"
Preflight builds,Assess,Techniques,TRUE,"<p>Even though we strongly advocate in favor of CI rather than <a href=""/radar/techniques/gitflow"">Gitflow</a>, we know that <a href=""https://trunkbaseddevelopment.com/committing-straight-to-the-trunk/"">committing straight to the trunk</a> and running the CI on a master branch can be ineffective if the team is too big, the builds are slow or flaky, or the team lacks the discipline to run the full test suite locally. In this situation a red build can block multiple devs or pairs of devs. Instead of fixing the underlying root cause — slow builds, the inability to run tests locally or monolithic architectures that necessitate many people working in the same area — teams usually rely on feature branches to bypass these issues. We discourage feature branches, given they may require significant effort to resolve merge conflicts, and they introduce longer feedback loops and potential bugs during conflict resolution. Instead, we propose using <strong>preflight builds</strong> as an alternative: these are pull request–based builds for “micro branches” that live only for the duration of the pipeline run, with the branch opened for every commit. To help automate this workflow, we've come across bots such as <a href=""https://bors.tech/"">Bors</a>, which automates merging to master and branch deletion in case the mini branch build succeeds. We're assessing this flow, and you should too; but don't use this to solve the wrong problem, as it can lead to misuse of branches and may cause more harm than benefit.</p>"
Cloud lift and shift,Hold,Techniques,FALSE,"<p>It is rather curious, that after over a decade of industry experience with cloud migration, we still feel it's necessary to call out <strong>cloud lift and shift</strong>; a practice that views cloud simply as a hosting solution, resulting in the replication of an existing architecture, security practices and IT operational models in the cloud. This fails to realize the cloud's promises of agility and digital innovation. A cloud migration requires intentional change across multiple axes toward a cloud-native state, and depending on the unique migration circumstances, each organization might end up somewhere on the spectrum from cloud lift and shift to cloud native. Systems architecture, for example, is one of the pillars of delivery agility and often requires change. The temptation to simply <a href=""https://cloud.google.com/migrate/anthos/docs/anthos-migrate-benefits"">lift and shift existing systems as containers</a> to the cloud can be strong. While this tactic can speed up cloud migration, it falls short when it comes to creating agility and delivering features and value. Enterprise security in the cloud is fundamentally different from traditional perimeter-based security through firewalls and zoning, and it demands a journey toward <a href=""/radar/techniques/zero-trust-architecture-zta"">zero trust architecture</a>. The IT operating model too has to be reformed to safely provide cloud services through self-serve automated platforms and empower teams to take more of the operational responsibility and gain autonomy. Last but not least, organizations must build a foundation to enable continuous change, such as creating pipelines with continuous testing of applications and infrastructure as a part of the migration. These will help the migration process, result in a more robust and well-factored system and give organizations a way to continue to evolve and improve their systems.</p>"
Legacy migration feature parity,Hold,Techniques,FALSE,"<p>We find that more and more organizations need to replace aging legacy systems to keep up with the demands of their customers (both internal and external). One antipattern we keep seeing is <strong>legacy migration feature parity</strong> , the desire to retain feature parity with the old. We see this as a huge missed opportunity. Often the old systems have bloated over time, with many features unused by users (50% according to a <a href=""https://www.standishgroup.com/sample_research_files/Exceeding%20Value_Layout.pdf"">2014 Standish Group report</a>) and business processes that have evolved over time. Replacing these features is a waste. Our advice: Convince your customers to take a step back and understand what their users currently <em>need</em> and prioritize these needs against business outcomes and metrics — which often is easier said than done. This means conducting user research and applying modern product development practices rather than simply replacing the existing ones.</p>"
Log aggregation for business analytics,Hold,Techniques,TRUE,"<p>Several years ago, a new generation of log aggregation platforms emerged that were capable of storing and searching over vast amounts of log data to uncover trends and insights in operational data. <a href=""/radar/tools/splunk"">Splunk</a> was the most prominent but by no means the only example of these tools. Because these platforms provide broad operational and security visibility across the entire estate of applications, administrators and developers have grown increasingly dependent on them. This enthusiasm spread as stakeholders discovered that they could use <strong>log aggregation for business analytics</strong>. However, business needs can quickly outstrip the flexibility and usability of these tools. Logs intended for technical observability are often inadequate to infer deep customer understanding. We prefer either to use tools and metrics designed for customer analytics or to take a more event-driven approach to observability where both business and operational events are collected and stored in a way they can be replayed and processed by more purpose-built tools.</p>"
Long-lived branches with Gitflow,Hold,Techniques,FALSE,"<p>Five years ago we highlighted the problems with <strong>long-lived branches with Gitflow</strong>. Essentially, long-lived branches are the opposite of continuously integrating all changes to the source code, and in our experience continuous integration is the better approach for most kinds of software development. Later we extended our caution to <a href=""/radar/techniques/gitflow"">Gitflow</a> itself, because we saw teams using it almost exclusively with long-lived branches. Today, we still see teams in settings where continuous delivery of web-based systems is the stated goal being drawn to long-lived branches. So we were delighted that the author of Gitflow has now added a note to his <a href=""https://nvie.com/posts/a-successful-git-branching-model/"">original article</a>, explaining that Gitflow was not intended for such use cases.</p>"
Snapshot testing only,Hold,Techniques,TRUE,"<p>The value of snapshot testing is undeniable when working with legacy systems by ensuring that the system continues to work and the legacy code doesn't break. However, we're seeing the common, rather harmful practice of using <strong>snapshot testing only</strong> as the primary test mechanism. Snapshot tests validate the exact result generated in the DOM by a component, not the component's behavior; therefore, it can be weak and unreliable, fostering the ""only delete the snapshot and regenerate it"" bad practice. Instead, you should test the logic and behavior of the components emulating what users would do. This mindset is encouraged by tools in the <a href=""https://testing-library.com/docs/guiding-principles"">Testing Library</a> family.</p>"
.NET Core,Adopt,Platforms,FALSE,"<p>We previously had <strong>.NET Core</strong> in Adopt, indicating that it had become our default for .NET projects. But we felt it's worth again calling attention to .NET Core. With the release of .NET Core 3.<em>x</em> last year, the bulk of the features from .NET Framework have now been ported into .NET Core. With the announcement that <a href=""https://devblogs.microsoft.com/dotnet/introducing-net-5"">.NET Framework is on its last release</a>, Microsoft have reinforced the view that <a href=""https://devblogs.microsoft.com/dotnet/net-core-is-the-future-of-net/"">.NET Core is the future of .NET</a>. Microsoft has done a lot of work to make .NET Core <a href=""https://devblogs.microsoft.com/dotnet/using-net-and-docker-together-dockercon-2019-update/"">container friendly</a>. Most of our .NET Core–based projects target Linux and are often deployed as containers. The upcoming <a href=""https://devblogs.microsoft.com/dotnet/introducing-net-5/"">.NET 5</a> release looks promising, and we're looking forward to it.</p>"
Istio,Adopt,Platforms,FALSE,"<p>If you're building and operating a scaled <a href=""https://martinfowler.com/articles/microservices.html"">microservices</a> architecture and have embraced <a href=""/radar/platforms/kubernetes"">Kubernetes</a>, adopting <a href=""/radar/techniques/service-mesh"">service mesh</a> to manage all cross-cutting aspects of running the architecture is a default position. Among various implementations of service mesh, <strong><a href=""https://istio.io"">Istio</a></strong> has gained majority adoption. It has a rich feature set, including service discovery, traffic management, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency. Its user experience has been improved in its latest releases, because of its ease of installation and control panel architecture. Istio has lowered the bar for implementing large-scale microservices with operational quality for many of our clients, while admitting that operating your own Istio and Kubernetes instances requires adequate knowledge and internal resources which is not for the fainthearted.</p>"
Anka,Trial,Platforms,FALSE,"<p><strong><a href=""https://ankadoc.bitbucket.io/"">Anka</a></strong> is a set of tools to create, manage, distribute, build and test macOS reproducible virtual environments for iOS and macOS. It brings Docker-like experience to macOS environments: instant start, CLI to manage virtual machines and registry to version and tag virtual machines for distribution. We've used Anka to build a macOS private cloud for a client. This tool is worth considering when virtualizing iOS and macOS environments.</p>"
Argo CD,Trial,Platforms,TRUE,"<p>Without making a judgment of the GitOps technique, we'd like to talk about <strong><a href=""https://argoproj.github.io/argo-cd/"">Argo CD</a></strong> within the scope of deploying and monitoring applications in <a href=""/radar/platforms/kubernetes"">Kubernetes</a> environments. Based on its ability to automate the deployment of the desired application state in the specified target environments in Kubernetes and our good experience with troubleshooting failed deployments, verifying logs and monitoring deployment status, we recommend you give Argo CD a try. You can even see graphically what is going on in the cluster, how a change is propagated and how pods are created and destroyed in real time.</p>"
Crowdin,Trial,Platforms,FALSE,"<p>Most of the projects with multilingual support start with development teams building features in one language and managing the rest through offline translation via emails and spreadsheets. Although this simple setup works, things can quickly get out of hand. You may have to keep answering the same questions for different language translators, sucking the energy out of the collaboration between translators, proofreaders and the development team. <strong><a href=""https://crowdin.com"">Crowdin</a></strong> is one of a handful of platforms that help in streamlining the localization workflow of your project. With Crowdin the development team can continue building features, while the platform streamlines the text that needs translation into an online workflow. We like that Crowdin nudges the teams to continuously and incrementally incorporate translations rather than managing them in large batches toward the end.</p>"
Cypress,Adopt,Tools,FALSE,"<p><strong><a href=""http://www.cypress.io/"">Cypress</a></strong> is still a favorite among our teams where developers manage end-to-end tests themselves, as part of a healthy <a href=""https://martinfowler.com/articles/practical-test-pyramid.html#End-to-endTests"">test pyramid</a>, of course. We decided to call it out again in this Radar because recent versions of Cypress have added <a href=""https://cypress.io/blog/2020/02/06/introducing-firefox-and-edge-support-in-cypress-4-0/"">support for Firefox</a>, and we strongly suggest testing on multiple browsers. The dominance of Chrome and Chromium-based browsers has led to a worrying trend of teams seemingly only testing with Chrome which can lead to <a href=""https://twitter.com/mike_conley/status/1245797292453609478"">nasty surprises</a>.</p>"
Figma,Adopt,Tools,FALSE,"<p><strong><a href=""https://www.figma.com/"">Figma</a></strong> has demonstrated to be the go-to tool for collaborative design, not only for designers but for multidisciplinary teams too; it allows developers and other roles to view and comment on designs through the browser without the desktop version. Compared to its competitors (e.g., Invision or Sketch) which have you use more than one tool for versioning, collaborating and design sharing, Figma puts together all of these features in one tool that makes it easier for our teams to discover new ideas together. Our teams find Figma very useful, especially in remote and distributed design work enablement and facilitation. In addition to its real-time design and collaboration capabilities, Figma also offers an API that helps to improve the <a href=""/radar/techniques/designops"">DesignOps</a> process.</p>"
Dojo,Trial,Tools,TRUE,"<p>A few years ago, Docker — and containers in general — radically changed how we think about packaging, deploying and running our applications. But despite this improvement in production, developers still spend a lot of time setting up development environments and regularly run into ""but it works on my machine"" style problems. <strong><a href=""https://github.com/kudulab/dojo"">Dojo</a></strong> aims to fix this by creating standard development environments, versioned and released as Docker images. Several of our teams use Dojo to streamline developing, testing and building code from local development through production pipelines.</p>"
DVC,Trial,Tools,TRUE,"<p>In 2018 we mentioned <strong><a href=""https://dvc.org/"">DVC</a></strong> in conjunction with the <a href=""/radar/techniques/versioning-data-for-reproducible-analytics"">versioning data for reproducible analytics</a>. Since then it has become a favorite tool for managing experiments in machine learning (ML) projects. Since it's based on Git, DVC is a familiar environment for software developers to bring their engineering practices to ML practice. Because it versions the code that processes data along with the data itself and tracks stages in a pipeline, it helps bring order to the modeling activities without interrupting the analysts’ flow.</p>"
Experiment tracking tools for machine learning,Trial,Tools,FALSE,"<p>The day-to-day work of machine learning often boils down to a series of experiments in selecting a modeling approach and the network topology, training data and optimizing or tweaking the model. Data scientists must use experience and intuition to hypothesize changes and then measure the impact those changes have on the overall performance of the model. As this practice has matured, our teams have found an increasing need for <strong>experiment tracking tools for machine learning</strong>. These tools help investigators keep track of the experiments and work through them methodically. Although no clear winner has emerged, tools such as <a href=""https://mlflow.org/"">MLflow</a> and platforms such as <a href=""https://comet.ml"">Comet</a> or <a href=""https://neptune.ml"">Neptune</a> have introduced rigor and repeatability into the entire machine learning workflow.</p>"
Goss,Trial,Tools,TRUE,"<p>We mentioned <strong><a href=""https://github.com/aelsabbahy/goss"">Goss</a></strong>, a tool for <a href=""/radar/techniques/provisioning-testing"">provisioning testing</a>, in passing in previous Radars, for example, when describing the technique of <a href=""/radar/techniques/tdd-ing-containers"">TDD'ing containers</a>. Although Goss isn't always an alternative to <a href=""/radar/tools/serverspec"">Serverspec</a>, simply because it doesn't offer the same amount of features, you may want to consider it when its features meet your needs, especially since it comes as a small, self-contained binary (rather than requiring a Ruby environment). A common anti-pattern with using tools such as Goss is double-entry bookkeeping, where each change in the actual infrastructure as code files requires a corresponding change in the test assertions. Such tests are maintenance heavy and because of the close correspondence between code and test, failures mostly occur when an engineer updates one side and forgets the other. And these tests rarely catch genuine problems.</p>"
Jaeger,Trial,Tools,FALSE,"<p><strong><a href=""https://github.com/jaegertracing/jaeger"">Jaeger</a></strong> is an open source distributed tracing system. Similar to <a href=""/radar/tools/zipkin"">Zipkin</a>, it's been inspired by the Google <a href=""https://ai.google/research/pubs/pub36356"">Dapper</a> paper and complies with <a href=""/radar/platforms/opentelemetry"">OpenTelemetry</a>. We've used Jaeger successfully with <a href=""/radar/platforms/istio"">Istio</a> and <a href=""https://www.envoyproxy.io/"">Envoy</a> on Kubernetes and like its <a href=""https://github.com/jaegertracing/jaeger-ui"">UI</a>. Jaeger exposes tracing metrics in the <a href=""/radar/tools/prometheus"">Prometheus</a> format so they can be made available to other tools. However, a new generation of tools such as <a href=""/radar/tools/honeycomb"">Honeycomb</a> integrates traces and metrics into a single observability stream for simpler aggregate analysis. Jaeger joined <a href=""https://www.cncf.io/blog/2017/09/13/cncf-hosts-jaeger/"">CNCF</a> in 2017 and has recently been elevated to CNCF's highest level of maturity, indicating its widespread deployment into production systems.</p>"
k9s,Trial,Tools,TRUE,"<p>We continue to be ardent supporters of <a href=""/radar/techniques/infrastructure-as-code"">infrastructure as code</a>, and we continue to believe that a robust monitoring solution is a prerequisite for operating distributed applications. Sometimes an interactive tool such as the AWS web console can be a useful addition. It allows us to explore all kinds of resources in an ad-hoc fashion without having to remember every single obscure command. Using an interactive tool to make manual modifications on the fly is still a questionable practice, though. For <a href=""/radar/platforms/kubernetes"">Kubernetes</a> we now have <strong><a href=""https://k9scli.io/"">k9s</a></strong>, which provides an interactive interface for basically everything that kubectl can do. And to boot, it's not a web application but runs inside a terminal window, evoking fond memories of <a href=""https://en.wikipedia.org/wiki/Midnight_Commander"">Midnight Commander</a> for some of us.</p>"
kind,Trial,Tools,TRUE,"<p><strong><a href=""https://github.com/kubernetes-sigs/kind"">kind</a></strong> is a tool for running local <a href=""/radar/platforms/kubernetes"">Kubernetes</a> clusters using Docker container nodes. With <a href=""https://github.com/kubernetes/test-infra/tree/master/kubetest"">kubetest</a> integration, kind makes it easy to do end-to-end testing on Kubernetes. We've used kind to create ephemeral Kubernetes clusters to test Kubernetes resources such as Operators and Custom Resource Definitions (CRDs) in our CI pipelines.</p>"
mkcert,Trial,Tools,TRUE,"<p><strong><a href=""https://github.com/FiloSottile/mkcert"">mkcert</a></strong> is a convenient tool for creating locally trusted development certificates. Using certificates from real certificate authorities (CAs) for local development can be challenging if not impossible (for hosts such as example.test, localhost or 127.0.0.1). In such situations self-signed certificates may be your only option. mkcert lets you generate self-signed certificates and installs the local CA in the system root store. For anything other than local development and testing, we strongly recommend using certificates from real CAs to avoid trust issues.</p>"
MURAL,Trial,Tools,TRUE,"<p><strong><a href=""https://www.mural.co/"">MURAL</a></strong> describes itself as a ""digital workspace for visual collaboration"" and allows teams to interact with a shared workspace based on a whiteboard/sticky notes metaphor. Its features include voting, commenting, notes and ""follow the presenter."" We particularly like the template feature that allows a facilitator to design and then reuse guided sessions with a team. Each of the major collaboration suites have a tool in this space (for example, <a href=""https://jamboard.google.com/"">Google Jamboard</a> and <a href=""https://www.microsoft.com/en-ca/microsoft-365/microsoft-whiteboard/digital-whiteboard-app"">Microsoft Whiteboard</a>) and these are worth investigating, but we've found MURAL to be slick, effective and flexible.</p>"
Open Policy Agent (OPA),Trial,Tools,FALSE,"<p><strong><a href=""https://www.openpolicyagent.org/"">Open Policy Agent (OPA)</a></strong> has rapidly become a favorable component of many distributed cloud-native solutions that we build for our clients. OPA provides a uniform framework and <a href=""https://www.openpolicyagent.org/docs/latest/#rego"">language</a> for declaring, enforcing and controlling policies for various components of a cloud-native solution. It's a great example of a tool that implements <a href=""/radar/techniques/security-policy-as-code"">security policy as code</a>. We've had a smooth experience using OPA in multiple scenarios, including deploying resources to K8s clusters, enforcing access control across services in a <a href=""/radar/techniques/service-mesh"">service mesh</a> and fine-grained security controls as code for accessing application resources. A recent commercial offering, <a href=""https://www.styra.com/"">Styra's Declarative Authorization Service (DAS)</a>, eases the adoption of OPA for enterprises by adding a management tool, or control plane, to OPA for K8s with a prebuilt policy library, impact analysis of the policies and logging capabilities. We look forward to maturity and extension of OPA beyond operational services to (big) data-centric solutions.</p>"
Optimal Workshop,Trial,Tools,FALSE,"<p>UX research demands data collection and analysis to make better decisions about the products we need to build. Our teams find <strong><a href=""https://www.optimalworkshop.com"">Optimal Workshop</a></strong> useful because it makes it easy to validate prototypes and configure tests for data collection and thus make better decisions. Features such as first-click, card sorting, or a heatmap of user interaction help to both validate prototypes and improve website navigation and information display. It's an ideal tool for distributed teams since it allows them to conduct remote research.</p>"
Phrase,Trial,Tools,TRUE,"<p>As mentioned in our description of <a href=""/radar/platforms/crowdin"">Crowdin</a>, you now have a choice of platforms to manage the translation of a product into multiple languages instead of emailing large spreadsheets. Our teams report positive experiences with <strong><a href=""https://phrase.com/"">Phrase</a></strong>, emphasizing that it's easy to use for all key user groups. Translators use a convenient browser-based UI. Managers can add new fields and synchronize translations with other teams in the same UI. Developers can access Phrase locally and from a build pipeline. A feature that deserves a specific mention is the ability to apply versioning to translations through tags, which makes it possible to compare the look of different translations inside the actual product.</p>"
ScoutSuite,Trial,Tools,FALSE,"<p><strong><a href=""https://github.com/nccgroup/ScoutSuite"">ScoutSuite</a></strong> is an expanded and updated tool based on Scout2 (featured in the Radar in 2018) that provides security posture assessment across <a href=""/radar/platforms/aws"">AWS</a>, <a href=""/radar/platforms/azure"">Azure</a>, <a href=""/radar/platforms/google-cloud-platform"">GCP</a> and other cloud providers. It works by automatically aggregating configuration data for an environment and applying rules to audit the environment. We've found this very useful across projects for doing point-in-time security assessments.</p>"
Visual regression testing tools,Trial,Tools,FALSE,"<p>Since we first mentioned <strong>visual regression testing tools</strong> in 2014, the use of the technique has spread and the tools landscape has evolved. <a href=""/radar/tools/backstopjs"">BackstopJS</a> remains an excellent choice with new features being added regularly, including support for running inside Docker containers. <a href=""/radar/tools/loki"">Loki</a> was featured in our previous Radar. <a href=""https://applitools.com/"">Applitools</a>, <a href=""https://crossbrowsertesting.com/"">CrossBrowserTesting</a> and <a href=""https://percy.io/"">Percy</a> are SaaS solutions. Another notable mention is <a href=""https://github.com/rsmbl"">Resemble.js</a>, an image diffing library. Although most teams use it indirectly as part of BackstopJS, some of our teams have been using it to analyze and compare images of web pages directly. In general, our experience shows that visual regression tools are less useful in the early stages when the interface goes through significant changes, but they certainly prove their worth as the product matures and the interface stabilizes.</p>"
Visual Studio Live Share,Trial,Tools,FALSE,"<p><strong><a href=""https://marketplace.visualstudio.com/items?itemName=MS-vsliveshare.vsliveshare-pack"">Visual Studio Live Share</a></strong> is a suite of extensions for <a href=""/radar/tools/visual-studio-code"">Visual Studio Code</a> and Visual Studio. At a time when teams are searching for good remote collaboration options, we want to call attention to the excellent tooling here. Live Share provides a good, low-latency remote-pairing experience, and requires significantly less bandwidth than the brute-force approach of sharing your entire desktop. Importantly, developers can work with their preferred configuration, extensions and key mappings during a pairing session. In addition to real-time collaboration for editing and debugging code, Live Share allows voice calls and sharing terminals and servers.</p>"
Apache Superset,Assess,Tools,TRUE,"<p><strong><a href=""https://superset.apache.org/"">Apache Superset</a></strong> is a great business intelligence (BI) tool for data exploration and visualization to work with large data lake and data warehouse setups. It works, for example, with <a href=""/radar/platforms/presto"">Presto</a>, <a href=""https://aws.amazon.com/athena/"">Amazon Athena</a> and <a href=""https://aws.amazon.com/redshift/"">Amazon Redshift</a> and can be nicely integrated with enterprise authentication. Moreover, you don't have to be a data engineer to use it; it’s meant to benefit all engineers exploring data in their everyday work. It's worth pointing out that Apache Superset is currently undergoing incubation at the Apache Software Foundation (ASF), meaning it's not yet fully endorsed by ASF.</p>"
ConfigCat,Assess,Tools,TRUE,"<p>If you're looking for a service to support dynamic feature toggles (and bear in mind that simple feature toggles work well too), check out <strong><a href=""https://configcat.com/"">ConfigCat</a></strong>. We'd describe it as ""like LaunchDarkly but cheaper and a bit less fancy"" and find that it does most of what we need. ConfigCat supports simple feature toggles, user segmentation, and A/B testing and has a generous free tier for low-volume use cases or those just starting out.</p>"
Gitpod,Assess,Tools,TRUE,"<p>You can build most software following a simple two-step process: check out a repository, and then run a single build script. The process of setting up a full coding environment can still be cumbersome, though. <strong><a href=""https://www.gitpod.io/"">Gitpod</a></strong> addresses this by providing cloud-based, ""ready-to-code"" environments for Github or GitLab repositories. It offers an IDE based on Visual Studio Code that runs inside the web browser. By default, these environments are launched on the Google Cloud Platform, although you can also deploy on-premise solutions. We see the immediate appeal, especially for open source software where this approach can lower the bar for casual contributors. However, it remains to be seen how viable this approach will be in corporate environments.</p>"
Gloo,Assess,Tools,TRUE,"<p>With the increasing adoption of <a href=""/radar/platforms/kubernetes"">Kubernetes</a> and <a href=""/radar/techniques/service-mesh"">service mesh</a>, API gateways have been experiencing an existential crisis in cloud-native distributed systems. After all, many of their capabilities (such as traffic control, security, routing and observability) are now provided by the cluster’s ingress controller and mesh gateway. <strong><a href=""https://www.solo.io/products/gloo/"">Gloo</a></strong> is a lightweight API gateway that embraces this change; it uses <a href=""https://www.envoyproxy.io/"">Envoy</a> as its gateway technology, while providing added value such as a cohesive view of the APIs to the external users and applications. It also provides an administrative interface for controlling Envoy gateways and runs and integrates with multiple service mesh implementations such as <a href=""https://linkerd.io/"">Linkerd</a>, <a href=""/radar/platforms/istio"">Istio</a> and <a href=""https://aws.amazon.com/app-mesh/"">AWS App Mesh</a>. While its open source implementation provides the basic capabilities expected from an API gateway, its enterprise edition has a more mature set of security controls such as API key management or integration with <a href=""/radar/tools/open-policy-agent-opa"">OPA</a>. Gloo is a promising lightweight API gateway that plays well with the ecosystem of cloud-native technology and architecture, while avoiding the API gateway trap of enabling business logic to glue APIs for the end user.</p>"
Lens,Assess,Tools,TRUE,"<p>One of the strengths of <a href=""/radar/platforms/kubernetes"">Kubernetes</a> is its flexibility and range of configuration possibilities along with the API-driven, programmable configuration mechanisms and command-line visibility and control using manifest files. However, that strength can also be a weakness: when deployments are complex or when managing multiple clusters, it can be difficult to get a clear picture of the overall status through command-line arguments and manifests alone. <strong><a href=""https://k8slens.dev/"">Lens</a></strong> attempts to solve this problem with an integrated environment for viewing the current state of the cluster and its workloads, visualizing cluster metrics and changing configurations through an embedded text editor. Rather than a simple point-and-click interface, Lens brings together the tools an administrator would run from the command line into a single, navigable interface. This tool is one of several approaches that are trying to tame the complexity of Kubernetes management. We've yet to see a clear winner in this space, but Lens strikes an interesting balance between a graphical UI and command-line–only tools.</p>"
Manifold,Assess,Tools,TRUE,"<p><strong><a href=""https://github.com/uber/manifold"">Manifold</a></strong> is a model-agnostic visual debugger for machine learning (ML). Model developers spend a significant amount of time on iterating and improving an existing model rather than creating a new one. By shifting the focus from model space to data space, Manifold supplements the existing performance metrics with a visual characteristics of the data set that influences the model performance. We think Manifold will be a useful tool to assess in the ML ecosystem.</p>"
Sizzy,Assess,Tools,TRUE,"<p>Building web applications that look just as intended on a large number of devices and screen sizes can be cumbersome. <strong><a href=""https://sizzy.co/"">Sizzy</a></strong> is a SaaS solution that shows many viewports in a single browser window. The application is rendered in all viewports simultaneously and interactions with the application are also synched across the viewports. In our experience interacting with an application in this way can make it easier to spot potential issues earlier, before a <a href=""/radar/tools/visual-regression-testing-tools"">visual regression testing tool</a> flags the issue in the build pipeline. We should mention, though, that some of our developers who tried Sizzy for a while did, on balance, prefer to work with the tooling provided by Chrome.</p>"
Snowpack,Assess,Tools,TRUE,"<p><strong><a href=""https://www.snowpack.dev/"">Snowpack</a></strong> is an interesting new entrant in the field of JavaScript build tools. The key improvement over other solutions is that Snowpack makes it possible to build applications with modern frameworks such as <a href=""/radar/languages-and-frameworks/react-js"">React.js</a>, <a href=""/radar/languages-and-frameworks/vue-js"">Vue.js</a>, and <a href=""/radar/languages-and-frameworks/angular"">Angular</a> without the need for a bundler. Cutting out the bundling step dramatically improves the feedback cycle during development because changes become available in the browser almost immediately. For this magic to work, Snowpack transforms the dependencies in <code>node_modules</code> into single JavaScript files in a new <code>web_modules</code> directory, from where they can be imported as an ECMAScript module (ESM). For IE11 and other browsers that don't support ESM, a workaround is available. Unfortunately, because no browser today can import CSS from JavaScript, using CSS modules is <a href=""https://www.snowpack.dev/#importing-css"">not straightforward</a>.</p>"
tfsec,Assess,Tools,TRUE,"<p>Security is everyone's concern and capturing risks early is always better than facing problems later on. In the <a href=""/radar/techniques/infrastructure-as-code"">infrastructure as code</a> space, where <a href=""/radar/tools/terraform"">Terraform</a> is an obvious choice to manage cloud environments, we now also have <strong><a href=""https://github.com/liamg/tfsec"">tfsec</a></strong>, which is a static analysis tool that helps to scan Terraform templates and find any potential security issues. It comes with preset rules for different cloud providers including <a href=""/radar/platforms/aws"">AWS</a> and <a href=""/radar/platforms/azure"">Azure</a>. We always like tools that help to mitigate security risks, and tfsec not only excels in identifying security risks, it's also easy to install and use.</p>"
React Hooks,Adopt,languages-and-frameworks,FALSE,"<p><strong><a href=""https://reactjs.org/docs/hooks-intro.html"">React Hooks</a></strong> have introduced a new approach to managing stateful logic; given React components have always been closer to functions than classes, Hooks have embraced this and brought state to the functions, instead of taking function as methods to the state with classes. Based on our experience, Hooks improve reuse of functionality among components and code readability. Given Hooks’ testability improvements, using <a href=""https://reactjs.org/docs/test-renderer.html"">React Test Renderer</a> and <a href=""/radar/languages-and-frameworks/react-testing-library"">React Testing Library</a>, and their growing community support, we consider them our approach of choice.</p>"
React Testing Library,Adopt,languages-and-frameworks,FALSE,"<p>The JavaScript world moves pretty fast, and as we gain more experience using a framework our recommendations change. The <strong><a href=""https://testing-library.com/"">React Testing Library</a></strong> is a good example of a framework that with deeper usage has eclipsed the alternatives to become the sensible default when testing React-based frontends. Our teams like the fact that tests written with this framework are less brittle than with alternative frameworks such as <a href=""/radar/languages-and-frameworks/enzyme"">Enzyme</a>, because you're encouraged to test component relationships individually as opposed to testing all implementation details. This mindset is brought by <a href=""https://testing-library.com/"">Testing Library</a> which React Testing Library is part of and which provides a whole family of libraries for <a href=""/radar/languages-and-frameworks/angular"">Angular</a> and <a href=""/radar/languages-and-frameworks/vue-js"">Vue.js</a>, for example.</p>"
XState,Assess,languages-and-frameworks,TRUE,"<p>We've featured several state management libraries in the Radar before, but <strong><a href=""https://xstate.js.org/docs/"">XState</a></strong> takes a slightly different approach. It's a simple JavaScript and <a href=""/radar/languages-and-frameworks/typescript"">TypeScript</a> framework for creating finite state machines and visualizing them as state charts. It integrates with the more popular reactive JavaScript frameworks (<a href=""/radar/languages-and-frameworks/vue-js"">Vue.js</a>, <a href=""/radar/languages-and-frameworks/ember-js"">Ember.js</a>, <a href=""/radar/languages-and-frameworks/react-js"">React.js</a> and <a href=""https://rxjs.dev/"">RxJS</a>) and is based on the W3C standard for finite state machines. Another notable feature is the serialization of machine definitions. One thing that we've found helpful when creating finite state machines in other contexts (particularly when writing game logic) is the ability to visualize states and their possible transitions; we like the fact that it's really easy to do this with XState's <a href=""https://xstate.js.org/viz/"">visualizer</a>.</p>"
Enzyme,Hold,languages-and-frameworks,FALSE,"<p>We don't always move deprecated tools to Hold in the Radar, but our teams feel strongly that <strong><a href=""http://airbnb.io/enzyme/"">Enzyme</a></strong> has been replaced for unit testing <a href=""/radar/languages-and-frameworks/react-js"">React</a> UI components by <a href=""https://testing-library.com/docs/intro"">React Testing Library</a>. Teams using Enzyme have found that its focus on testing component internals leads to brittle, unmaintainable tests.</p>"